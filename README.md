# ğŸ¦ Bank Churn Prediction - MLOps End-to-End Project

[![MLOps](https://img.shields.io/badge/MLOps-Automated-blue)]()
[![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED)]()
[![Jenkins](https://img.shields.io/badge/Jenkins-CI%2FCD-D24939)]()
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2)]()
[![Evidently](https://img.shields.io/badge/Evidently-Monitoring-FF6B6B)]()
[![Python](https://img.shields.io/badge/Python-3.9+-3776AB)]()

> **Master 2 Data Science - UniversitÃ© Claude Bernard Lyon 1**  
> Un pipeline MLOps complet pour la prÃ©diction du churn bancaire

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture MLOps](#-architecture-mlops)
- [Workflow AutomatisÃ©](#-workflow-automatisÃ©)
- [Performances du ModÃ¨le](#-performances-du-modÃ¨le)
- [Installation & DÃ©marrage](#-installation--dÃ©marrage)
- [Structure du Projet](#-structure-du-projet)
- [Notebooks](#-notebooks)
- [Technologies UtilisÃ©es](#-technologies-utilisÃ©es)
- [Monitoring et Drift Detection](#-monitoring-et-drift-detection)
- [Perspectives Futures](#-perspectives-futures)
- [Ã‰quipe](#-Ã©quipe)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **systÃ¨me complet de prÃ©diction du churn bancaire** avec un pipeline MLOps end-to-end. Il dÃ©montre l'application des meilleures pratiques MLOps incluant:

- **ExpÃ©rimentation ML** avec tracking via MLflow sur DagsHub
- **Pipeline CI/CD automatisÃ©** avec Jenkins et GitHub Webhooks
- **Monitoring de drift** avec Evidently AI
- **DÃ©ploiement containerisÃ©** avec Docker et Docker Compose
- **API REST** avec FastAPI et interface utilisateur Streamlit

### ğŸ“ Contexte AcadÃ©mique

**Programme:** Master 2 Data Science  
**Institution:** UniversitÃ© Claude Bernard Lyon 1  
**Objectif pÃ©dagogique:** MaÃ®triser l'ensemble du cycle de vie MLOps, de l'expÃ©rimentation Ã  la production

### ğŸ† RÃ©sultats ClÃ©s

- **ROC-AUC Score:** 0.993 (modÃ¨le LightGBM optimisÃ©)
- **F1-Score:** 0.919
- **Pipeline 100% automatisÃ©** depuis le push Git jusqu'au dÃ©ploiement
- **Monitoring en temps rÃ©el** avec dÃ©tection automatique de drift

---

## ğŸ—ï¸ Architecture MLOps

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ““ DÃ‰VELOPPEMENT & TRACKING                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Notebooks (3)  â†’  MLflow (DagsHub)  â†’  Model Registry         â”‚
â”‚  â€¢ preprocessing.ipynb                                           â”‚
â”‚  â€¢ modeling.ipynb     (ExpÃ©rimentation)                         â”‚
â”‚  â€¢ mlflow_tracking.ipynb                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ”„ VERSIONING & TRIGGER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GitHub Repository  â†’  Webhook  â†’  Jenkins Pipeline            â”‚
â”‚  (Code + Data)         (ngrok)      (Jenkinsfile)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ“Š MONITORING & VALIDATION                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Evidently AI  â†’  Drift Detection  â†’  Reports (HTML/JSON)      â”‚
â”‚  (Data Quality)   (KS Test)            (Port 9000)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ³ BUILD & DEPLOYMENT                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Docker Build  â†’  Docker Hub  â†’  docker-compose Deploy         â”‚
â”‚  (Multi-stage)    (Registry)      (3 services)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸš€ PRODUCTION SERVICES                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend (FastAPI)  |  Frontend (Streamlit)  |  Monitoring     â”‚
â”‚  :8000              |  :8501                 |  :9000           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Workflow AutomatisÃ©

### 1ï¸âƒ£ Phase DÃ©veloppement

#### **Notebooks de DÃ©veloppement**

Le projet est structurÃ© en **3 notebooks Jupyter** documentant le cycle complet:

1. **`preprocessing.ipynb`** - PrÃ©paration des donnÃ©es
   - Nettoyage et transformation
   - Feature engineering (5 nouvelles features)
   - Gestion des valeurs manquantes
   - Encoding des variables catÃ©gorielles
   - Stratification du dataset

2. **`modeling.ipynb`** - EntraÃ®nement des modÃ¨les
   - ModÃ¨les baseline (6 algorithmes)
   - Fine-tuning avec RandomizedSearchCV
   - Ensemble learning (Stacking & Voting)
   - Ã‰valuation comparative multi-mÃ©triques

3. **`mlflow_tracking.ipynb`** - Tracking et Registry
   - Logging de 20+ expÃ©rimentations
   - Comparaison des performances
   - SÃ©lection du meilleur modÃ¨le
   - Enregistrement dans Model Registry

#### **MLflow sur DagsHub**

- ğŸ“Š **Tracking centralisÃ©:** https://dagshub.com/karrayyessine1/MLOps_Project/experiments
- ğŸ† **Meilleur modÃ¨le:** LightGBM (ROC-AUC: 0.9931)
- ğŸ“¦ **Model Registry:** Versioning et staging des modÃ¨les
- ğŸ”— **Collaboration:** Partage des expÃ©rimentations entre membres de l'Ã©quipe

---

### 2ï¸âƒ£ Phase CI/CD - Jenkins

#### **Configuration du Pipeline**

**Jenkins URL:** https://3fc290848417.ngrok-free.app â†’ http://localhost:8080

Le pipeline Jenkins s'exÃ©cute automatiquement Ã  chaque push Git via webhook:

```groovy
pipeline {
    agent any
    
    stages {
        stage('ğŸ“¥ Clone Repository') {
            // Clone depuis GitHub
        }
        
        stage('ğŸ Setup Python Environment') {
            // Installation des dÃ©pendances
        }
        
        stage('ğŸ“Š Register Best Model') {
            // Copie du modÃ¨le depuis model_registry/
        }
        
        stage('ğŸ“Š Data Drift Monitoring') {
            // Evidently: dÃ©tection de drift
        }
        
        stage('ğŸ“„ Archive Reports') {
            // Sauvegarde rapports HTML/JSON
        }
        
        stage('ğŸ“Š Publish Reports') {
            // Container nginx pour visualisation
        }
        
        stage('ğŸ³ Build Docker Images') {
            // Build Backend + Frontend
        }
        
        stage('ğŸš€ Push to Docker Hub') {
            // Push vers yessinekarray/*
        }
        
        stage('ğŸš€ Deploy Application') {
            // docker-compose up
        }
        
        stage('ğŸ¥ Health Check') {
            // Validation des services
        }
    }
}
```

#### **DÃ©clenchement Automatique**

**Configuration GitHub Webhook:**
- **URL:** `https://3fc290848417.ngrok-free.app/github-webhook/`
- **Events:** Push events
- **Content-Type:** application/json

**Flux:**
```
Nouveau push â†’ GitHub Webhook â†’ ngrok â†’ Jenkins â†’ Pipeline automatique
```

---

### 3ï¸âƒ£ Phase Monitoring - Evidently AI

#### **DÃ©tection Automatique de Drift**

Le systÃ¨me de monitoring gÃ©nÃ¨re automatiquement:

- ğŸ“Š **Data Drift Report** - Distribution des features (rÃ©fÃ©rence vs production)
- ğŸ“ˆ **Performance Report** - MÃ©triques du modÃ¨le en temps rÃ©el
- âš ï¸ **Alerts** - Notifications si drift dÃ©tectÃ©
- ğŸŒ **Dashboard** - Rapports HTML accessibles sur http://localhost:9000

#### **Tests AutomatisÃ©s**

```python
# Le monitoring dÃ©tecte automatiquement le fichier le plus rÃ©cent
latest_file = get_latest_prod_file("monitoring/data/")

# Tests exÃ©cutÃ©s:
âœ“ Data Stability Test
âœ“ Column Drift Test (Kolmogorov-Smirnov)
âœ“ Dataset Drift Test
âš ï¸ Alert si drift > seuil configurÃ©
```

#### **Fichiers SurveillÃ©s**

```
monitoring/data/
â”œâ”€â”€ churn2.csv              # Dataset de rÃ©fÃ©rence (baseline)
â””â”€â”€ prod_batch_*.csv        # Batches de production (dÃ©tection auto)
```

---

### 4ï¸âƒ£ Phase DÃ©ploiement - Docker

#### **Architecture Multi-Container**

```yaml
services:
  backend:
    image: yessinekarray/churn-backend:latest
    ports: ["8000:8000"]
    volumes: ["./models:/app/processors/models"]
    
  frontend:
    image: yessinekarray/churn-frontend:latest
    ports: ["8501:8501"]
    depends_on: [backend]
    
  monitoring:
    image: monitoring-reports:latest
    ports: ["9000:80"]
```

#### **Optimisation - ModÃ¨le Externe**

**ProblÃ¨me:** ModÃ¨le de 1 GB â†’ Image Docker trop lourde  
**Solution:** ModÃ¨le stockÃ© sur host, montÃ© via Docker volume  
**RÃ©sultat:** Images Docker ~100 MB, push/pull rapides

---

## ğŸ“Š Performances du ModÃ¨le

### **Meilleur ModÃ¨le: LightGBM (OptimisÃ©)**

| MÃ©trique      | Score  | InterprÃ©tation                                  |
|---------------|--------|-------------------------------------------------|
| **ROC-AUC**   | 0.9931 | Excellente discrimination des classes           |
| **F1-Score**  | 0.9192 | Ã‰quilibre optimal Precision/Recall              |
| **Precision** | 0.9023 | 90% des prÃ©dictions "Churn" sont correctes      |
| **Recall**    | 0.9372 | 94% des vrais churners sont dÃ©tectÃ©s            |
| **Accuracy**  | 0.9650 | Performance globale trÃ¨s Ã©levÃ©e                 |

### **Comparaison des ModÃ¨les**

Tous les modÃ¨les ont Ã©tÃ© trackÃ©s dans MLflow avec mÃ©triques complÃ¨tes:

**Baseline Models:**
- Logistic Regression
- Random Forest
- Gradient Boosting
- XGBoost
- LightGBM â­
- CatBoost

**Fine-Tuned Models:**
- Optimisation via RandomizedSearchCV (40 itÃ©rations Ã— 5-fold CV)
- AmÃ©lioration moyenne: +2.5% ROC-AUC

**Ensemble Models:**
- Stacking Classifier (LogReg meta-learner)
- Voting Classifier (Soft voting)

---

## ğŸš€ Installation & DÃ©marrage

### **PrÃ©requis**

- Docker & Docker Compose (â‰¥20.10)
- Git
- Python 3.9+ (pour dÃ©veloppement local)
- Jenkins (pour CI/CD)
- ngrok (pour webhook GitHub)

### **Option 1: DÃ©ploiement Rapide (Docker)**

```bash
# 1. Cloner le repository
git clone https://github.com/YessineK/Mlops_Project.git
cd Mlops_Project

# 2. PrÃ©parer le modÃ¨le (copie depuis registry)
mkdir -p models
cp notebooks/model_registry/best_model_final.pkl models/

# 3. Lancer l'application complÃ¨te
docker-compose up --build
```

**Services disponibles:**
- ğŸ¨ **Frontend:** http://localhost:8501
- ğŸ”Œ **API Backend:** http://localhost:8000/docs (Swagger UI)
- ğŸ“Š **Monitoring:** http://localhost:9000

### **Option 2: Setup Complet avec CI/CD**

#### **1. Installation Jenkins**

```bash
docker run -d -p 8080:8080 -p 50000:50000 \
  -v jenkins_home:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  --name jenkins jenkins/jenkins:lts

# RÃ©cupÃ©rer le mot de passe initial
docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword
```

#### **2. Configuration Jenkins**

1. AccÃ©der Ã  http://localhost:8080
2. Installer les plugins recommandÃ©s + **Docker Pipeline**
3. CrÃ©er un nouveau projet **Pipeline**
4. Configuration:
   - **SCM:** Git
   - **Repository URL:** https://github.com/YessineK/Mlops_Project.git
   - **Branch:** main
   - **Build Triggers:** âœ… GitHub hook trigger for GITScm polling
5. Ajouter les credentials Docker Hub:
   - ID: `docker-hub-credentials`
   - Type: Username with password

#### **3. Exposition Jenkins avec ngrok**

```bash
# Installer ngrok
brew install ngrok  # macOS
# ou tÃ©lÃ©charger depuis https://ngrok.com/download

# Exposer Jenkins
ngrok http 8080

# Note: L'URL gÃ©nÃ©rÃ©e (ex: https://3fc290848417.ngrok-free.app)
```

#### **4. Configuration GitHub Webhook**

1. Aller dans **Settings** â†’ **Webhooks** â†’ **Add webhook**
2. Configuration:
   - **Payload URL:** `https://YOUR_NGROK_URL/github-webhook/`
   - **Content type:** application/json
   - **Events:** âœ… Just the push event
   - **Active:** âœ…

#### **5. Test du Pipeline**

```bash
# Faire un commit test
echo "test" >> README.md
git add .
git commit -m "test: trigger Jenkins pipeline"
git push origin main

# Jenkins devrait dÃ©marrer automatiquement
# VÃ©rifier: https://YOUR_NGROK_URL
```

---

## ğŸ“ Structure du Projet

```
Mlops_Project/
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                       # DÃ©veloppement ML
â”‚   â”œâ”€â”€ preprocessing.ipynb             # Ã‰tape 1: PrÃ©paration donnÃ©es
â”‚   â”œâ”€â”€ modeling.ipynb                  # Ã‰tape 2: EntraÃ®nement modÃ¨les
â”‚   â”œâ”€â”€ mlflow_tracking.ipynb           # Ã‰tape 3: Tracking & Registry
â”‚   â”œâ”€â”€ model_registry/                 # Meilleurs modÃ¨les sauvegardÃ©s
â”‚   â”‚   â”œâ”€â”€ best_model_final.pkl        # LightGBM (1 GB)
â”‚   â”‚   â””â”€â”€ metadata.json               # MÃ©tadonnÃ©es du modÃ¨le
â”‚   â””â”€â”€ processors/                     # Preprocessors versionnÃ©s
â”‚       â”œâ”€â”€ preprocessor.pkl
â”‚       â”œâ”€â”€ feature_names.pkl
â”‚       â””â”€â”€ preprocessed_data.pkl
â”‚
â”œâ”€â”€ ğŸ backend/                         # API FastAPI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py                     # Endpoints REST
â”‚   â”‚   â””â”€â”€ processors/
â”‚   â”‚       â”œâ”€â”€ models/                 # ModÃ¨les (via volume)
â”‚   â”‚       â””â”€â”€ preprocessor.pkl
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ¨ frontend/                        # Interface Streamlit
â”‚   â”œâ”€â”€ app.py                          # UI utilisateur
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“Š monitoring/                      # Evidently AI
â”‚   â”œâ”€â”€ prepare_data.py                 # DÃ©tection auto dernier fichier
â”‚   â”œâ”€â”€ score_data.py                   # Scoring production
â”‚   â”œâ”€â”€ run_monitoring.py               # GÃ©nÃ©ration rapports
â”‚   â”œâ”€â”€ Dockerfile                      # Container nginx
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ churn2.csv                  # Reference dataset
â”‚       â””â”€â”€ prod_batch_*.csv            # Production batches
â”‚
â”œâ”€â”€ âš™ï¸ Jenkins/
â”‚   â””â”€â”€ register_best_model.py          # Script copie modÃ¨le â†’ backend
â”‚
â”œâ”€â”€ ğŸ“¦ models/                          # ModÃ¨les pour dÃ©ploiement (host)
â”‚   â””â”€â”€ best_model_final.pkl            # MontÃ© via Docker volume
â”‚
â”œâ”€â”€ ğŸ³ docker-compose.yml               # Orchestration services
â”œâ”€â”€ ğŸ“‹ Jenkinsfile                      # Pipeline CI/CD
â”œâ”€â”€ ğŸ“„ README.md                        # Ce fichier
â”œâ”€â”€ ğŸ“„ requirements.txt                 # DÃ©pendances Python
â””â”€â”€ .gitignore
```

---

## ğŸ““ Notebooks

### **1. preprocessing.ipynb**

**Objectif:** PrÃ©paration et nettoyage des donnÃ©es

**Ã‰tapes principales:**
- Import et exploration des donnÃ©es (`churn2.csv`)
- Nettoyage:
  - Suppression colonnes vides
  - Conversion types (categorical encoding)
  - Gestion valeurs manquantes ("Unknown" â†’ imputation)
- Feature Engineering:
  - `tenure_per_age`
  - `utilisation_per_age`
  - `credit_lim_per_age`
  - `total_trans_amt_per_credit_lim`
  - `total_trans_ct_per_credit_lim`
- Preprocessing pipeline:
  - StandardScaler pour variables numÃ©riques
  - OneHotEncoder pour variables catÃ©gorielles
- Sauvegarde artifacts:
  - `preprocessor.pkl`
  - `feature_names.pkl`
  - `preprocessed_data.pkl`

**Sorties:**
- Dataset preprocessÃ© prÃªt pour modeling
- 28 features finales (23 originales + 5 engineerÃ©es)
- Train/Test split stratifiÃ© (80/20)

---

### **2. modeling.ipynb**

**Objectif:** EntraÃ®nement, optimisation et sÃ©lection du meilleur modÃ¨le

**Ã‰tapes principales:**

1. **Baseline Models** (6 modÃ¨les):
   ```python
   - Logistic Regression
   - Random Forest
   - Gradient Boosting
   - XGBoost
   - LightGBM
   - CatBoost
   ```

2. **Fine-Tuning** (RandomizedSearchCV):
   - 40 itÃ©rations Ã— 5-fold CV
   - Optimisation sur PR-AUC (mÃ©trique clÃ© churn)
   - Recherche d'hyperparamÃ¨tres:
     - Learning rate: [0.01, 0.02, 0.03, 0.05]
     - N_estimators: [400, 600, 800, 1000]
     - Max_depth, min_samples, etc.

3. **Ensemble Learning**:
   - Stacking Classifier (LogReg meta-learner)
   - Voting Classifier (Soft voting)

4. **Ã‰valuation Multi-MÃ©triques**:
   - Accuracy, Precision, Recall
   - F1-Score, ROC-AUC, PR-AUC
   - Courbes ROC et Precision-Recall
   - Matrices de confusion

5. **Sauvegarde du Meilleur ModÃ¨le**:
   - Score composite pondÃ©rÃ©:
     - ROC-AUC: 35%
     - F1-Score: 30%
     - Recall: 25%
     - Precision: 10%

**Sorties:**
- `best_model_final.pkl` (LightGBM optimisÃ©)
- `model_comparison_final.csv`
- `model_improvements.csv`
- Graphiques de comparaison

---

### **3. mlflow_tracking.ipynb**

**Objectif:** Tracking MLflow et gestion du Model Registry

**Ã‰tapes principales:**

1. **Configuration MLflow + DagsHub**:
   ```python
   MLFLOW_TRACKING_URI = "https://dagshub.com/karrayyessine1/MLOps_Project.mlflow"
   EXPERIMENT_NAME = "churn_prediction"
   ```

2. **Logging des ModÃ¨les**:
   - Production model (1 run)
   - Tuned models (6 runs)
   - Ensemble models (2 runs)
   - **Total: 9 runs trackÃ©es**

3. **MÃ©tadonnÃ©es LoggÃ©es**:
   - ParamÃ¨tres (hyperparamÃ¨tres, dataset)
   - MÃ©triques (accuracy, F1, ROC-AUC, etc.)
   - Artifacts (modÃ¨les .pkl)
   - DurÃ©e d'entraÃ®nement

4. **Model Registry Local**:
   ```
   model_registry/
   â”œâ”€â”€ Best_Churn_LightGBM/
   â”‚   â”œâ”€â”€ 1.0.0/
   â”‚   â”‚   â”œâ”€â”€ model.pkl
   â”‚   â”‚   â””â”€â”€ metadata.json
   â”‚   â””â”€â”€ production.pkl
   ```

5. **Lecture et Comparaison**:
   - Pandas DataFrame depuis MLflow
   - Tri par ROC-AUC
   - SÃ©lection du meilleur modÃ¨le

**Sorties:**
- Dashboard MLflow complet sur DagsHub
- Model Registry versionnÃ©
- Meilleur modÃ¨le prÃªt pour dÃ©ploiement

**AccÃ¨s Dashboard:**
- https://dagshub.com/karrayyessine1/MLOps_Project/experiments

---

## ğŸ”§ Technologies UtilisÃ©es

### **Machine Learning**

| Technologie | Usage | Version |
|-------------|-------|---------|
| **scikit-learn** | Preprocessing, baseline models | 1.3+ |
| **LightGBM** | Meilleur modÃ¨le (Gradient Boosting) | 4.0+ |
| **XGBoost** | Alternative Gradient Boosting | 2.0+ |
| **CatBoost** | Handling de features catÃ©gorielles | 1.2+ |
| **imbalanced-learn** | SMOTE (gestion dÃ©sÃ©quilibre) | 0.11+ |
| **pandas** | Manipulation de donnÃ©es | 2.0+ |
| **numpy** | Calculs numÃ©riques | 1.24+ |

### **MLOps & Tracking**

| Technologie | Usage | Version |
|-------------|-------|---------|
| **MLflow** | Experiment tracking, model registry | 2.8+ |
| **DagsHub** | Remote MLflow server (collaboration) | - |
| **Evidently AI** | Data drift detection, monitoring | 0.4+ |

### **CI/CD & Deployment**

| Technologie | Usage | Version |
|-------------|-------|---------|
| **Jenkins** | Pipeline automation (CI/CD) | 2.426+ |
| **Docker** | Containerization | 24.0+ |
| **Docker Compose** | Multi-container orchestration | 2.23+ |
| **Docker Hub** | Image registry | - |
| **GitHub Webhooks** | Auto-trigger Jenkins on push | - |
| **ngrok** | Expose Jenkins for webhook | 3.0+ |

### **Backend & Frontend**

| Technologie | Usage | Version |
|-------------|-------|---------|
| **FastAPI** | RESTful API (Python) | 0.104+ |
| **Streamlit** | Interactive web UI | 1.28+ |
| **uvicorn** | ASGI server | 0.24+ |
| **Pydantic** | Data validation | 2.5+ |

### **Monitoring & Reporting**

| Technologie | Usage | Version |
|-------------|-------|---------|
| **nginx** | Servir rapports HTML | 1.25+ |
| **matplotlib** | Visualisations statiques | 3.7+ |
| **seaborn** | Visualisations statistiques | 0.12+ |

---

## ğŸ“Š Monitoring et Drift Detection

### **Architecture de Monitoring**

```python
monitoring/
â”œâ”€â”€ prepare_data.py          # DÃ©tection auto dernier batch
â”œâ”€â”€ score_data.py            # Scoring avec modÃ¨le de production
â”œâ”€â”€ run_monitoring.py        # GÃ©nÃ©ration rapports Evidently
â””â”€â”€ data/
    â”œâ”€â”€ churn2.csv           # Reference dataset (baseline)
    â””â”€â”€ prod_batch_*.csv     # Production batches
```

### **Rapports GÃ©nÃ©rÃ©s**

#### **1. Data Drift Report**
- Comparaison distributions (reference vs current)
- Tests statistiques par feature (Kolmogorov-Smirnov)
- Visualisation des drifts dÃ©tectÃ©s

#### **2. Performance Report**
- MÃ©triques du modÃ¨le en production
- Comparaison avec baseline
- DÃ©gradation de performance

#### **3. Test Results (JSON)**
```json
{
  "data_stability": "PASS",
  "column_drift": "WARNING",
  "dataset_drift": "FAIL",
  "drifted_features": ["total_trans_ct", "avg_utilization_ratio"]
}
```

### **AccÃ¨s aux Rapports**

**Dashboard:** http://localhost:9000

Contenu:
- `monitoring_report.html` - Visualisation interactive du drift
- `performance_report.html` - MÃ©triques de performance
- `*.json` - RÃ©sultats des tests automatisÃ©s

### **Alerting (Future)**

Si drift dÃ©tectÃ© (seuil > 3 features):
1. ğŸ“§ Email aux data scientists
2. ğŸ“± Notification Slack
3. ğŸ”„ DÃ©clenchement auto-retraining (roadmap)

---

## ğŸ”® Perspectives Futures

### **Phase 1: Auto-Retraining** ğŸ¤–

**Workflow proposÃ©:**
```
Drift dÃ©tectÃ© (> seuil)
    â†“
Combine old data + new batch
    â†“
Train nouveau modÃ¨le
    â†“
Validation (compare performances vs modÃ¨le actuel)
    â†“
Si meilleur â†’ Deploy automatique
Sinon       â†’ Alerte Ã©quipe
```

**ImplÃ©mentation:**
- Nouveau stage Jenkins: "Auto-Retraining if Drift"
- Scripts: `retrain_with_new_data.py`, `validate_new_model.py`
- Seuil configurable: 3+ colonnes en drift

---

### **Phase 2: Model Storage Scalable** â˜ï¸

**ProblÃ¨me actuel:** ModÃ¨le 1GB montÃ© via volume Docker

**Solution proposÃ©e:**
- **MinIO** (S3-compatible, self-hosted)
- Backend tÃ©lÃ©charge modÃ¨le au dÃ©marrage
- Versioning avec tags (v1.0, v1.1, etc.)
- Rollback rapide en cas de problÃ¨me

**Architecture:**
```
MinIO (S3)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ churn_v1.0.pkl
â”‚   â”œâ”€â”€ churn_v1.1.pkl
â”‚   â””â”€â”€ churn_latest.pkl
```

### **Phase 3: A/B Testing** ğŸ§ª

**Objectif:** Comparer 2 versions du modÃ¨le en production

**ImplÃ©mentation:**
```python
# Traffic routing
if user_id % 2 == 0:
    model = load_model("v1.0")  # 50% traffic
else:
    model = load_model("v1.1")  # 50% traffic

# Tracking des performances
log_prediction(user_id, model_version, prediction, actual)
```

**MÃ©triques comparÃ©es:**
- ROC-AUC en production
- Latence moyenne
- Taux de faux positifs/nÃ©gatifs
- Feedback utilisateur

---

### **Phase 5: Real-Time Monitoring Dashboard** ğŸ“Š

**Stack proposÃ©:**
- **Grafana:** Visualisation temps rÃ©el
- **Prometheus:** Collecte mÃ©triques
- **Alerting:** Slack/Email

**MÃ©triques trackÃ©es:**
```
- Nombre de prÃ©dictions/min
- Latence P50/P95/P99
- Taux de drift par feature
- Distribution des prÃ©dictions
- Taux d'erreur API
- Utilisation CPU/MÃ©moire
```

**Alertes configurÃ©es:**
- Drift dÃ©tectÃ© sur >3 features
- Latence >500ms
- Taux d'erreur >1%
- DÃ©gradation ROC-AUC >5%

---


### **Dashboard Monitoring**

**URL:** http://localhost:9000

**Rapports disponibles:**

1. **monitoring_report.html**
   - Data Drift Analysis
   - Distribution plots (reference vs current)
   - Statistical tests results

2. **performance_report.html**
   - Model performance metrics
   - Confusion matrix
   - ROC curve & PR curve

3. **drift_tests.json**
   - Test results dÃ©taillÃ©s
   - Features en drift
   - Timestamps

---

### **MLflow Tracking**

**Dashboard:** https://dagshub.com/karrayyessine1/MLOps_Project/experiments

**FonctionnalitÃ©s:**
- ğŸ“Š Compare runs (mÃ©triques, paramÃ¨tres)
- ğŸ“ˆ Visualisation courbes de learning
- ğŸ“¦ Download artifacts (modÃ¨les, plots)
- ğŸ·ï¸ Tagging et notes sur runs
- ğŸ” Search & filter experiments

---

### **Master 2 Data Science - UniversitÃ© Claude Bernard Lyon 1**

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du Master 2 Data Science Ã  l'**UniversitÃ© Claude Bernard Lyon 1** (UCBL).

#### **Contributions principales:**

- **Architecture MLOps:** Design du pipeline end-to-end
- **DÃ©veloppement Notebooks:** Preprocessing, Modeling, MLflow Tracking
- **Configuration CI/CD:** Jenkins, Docker, GitHub Webhooks
- **Monitoring:** ImplÃ©mentation Evidently AI
- **DÃ©ploiement:** Docker Compose, services production

#### **Encadrement acadÃ©mique:**

- **Programme:** Master 2 Data Science
- **Institution:** UniversitÃ© Claude Bernard Lyon 1
- **AnnÃ©e:** 2025-2026

---


