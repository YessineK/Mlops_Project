# ğŸ¦ Bank Churn Prediction - MLOps End-to-End Project

[![MLOps](https://img.shields.io/badge/MLOps-Automated-blue)]()
[![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED)]()
[![Jenkins](https://img.shields.io/badge/Jenkins-CI%2FCD-D24939)]()
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2)]()
[![Evidently](https://img.shields.io/badge/Evidently-Monitoring-FF6B6B)]()

SystÃ¨me complet de prÃ©diction du churn bancaire avec pipeline MLOps automatisÃ© : tracking ML, monitoring de drift, CI/CD, et dÃ©ploiement containerisÃ©.

---

## ğŸ¯ Objectif du Projet

PrÃ©dire le risque de dÃ©part des clients bancaires en utilisant un modÃ¨le de Machine Learning performant (ROC-AUC: **0.993**), avec un pipeline MLOps complet pour assurer la **qualitÃ©**, la **traÃ§abilitÃ©**, et le **monitoring** du modÃ¨le en production.

---

## ğŸ—ï¸ Architecture MLOps ComplÃ¨te
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DÃ‰VELOPPEMENT & TRACKING                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Notebooks  â†’  MLflow (DagsHub)  â†’  Model Registry             â”‚
â”‚  (Exploration)   (Tracking)           (Versioning)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERSIONING & TRIGGER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GitHub Repository  â†’  Webhook  â†’  Jenkins Pipeline            â”‚
â”‚  (Code + Data)         (Auto)       (CI/CD)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITORING & VALIDATION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Evidently AI  â†’  Drift Detection  â†’  Auto-Retraining (Future) â”‚
â”‚  (Data Quality)   (Alerts)             (If Drift > Threshold)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BUILD & DEPLOYMENT                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Docker Images  â†’  Docker Hub  â†’  docker-compose Deploy        â”‚
â”‚  (Backend+Frontend) (Registry)     (Production)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRODUCTION SERVICES                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend API (FastAPI)  |  Frontend (Streamlit)  |  Monitoring  â”‚
â”‚  :8000                  |  :8501                 |  :9000        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Workflow MLOps AutomatisÃ©

### **1ï¸âƒ£ Phase DÃ©veloppement : ML Experimentation & Tracking**
```python
# notebooks/ - ExpÃ©rimentation des modÃ¨les
â”œâ”€â”€ 01_data_exploration.ipynb      # EDA + Feature Engineering
â”œâ”€â”€ 02_model_training.ipynb        # Training avec MLflow tracking
â”œâ”€â”€ 03_model_evaluation.ipynb      # Comparaison des modÃ¨les
â””â”€â”€ model_registry/                # Meilleur modÃ¨le versionnÃ©
    â””â”€â”€ best_model_final.pkl       # LightGBM (ROC-AUC: 0.993)
```

**MLflow sur DagsHub** :
- ğŸ“Š Track de **20+ expÃ©rimentations** (hyperparamÃ¨tres, mÃ©triques, artefacts)
- ğŸ† SÃ©lection automatique du meilleur modÃ¨le (ROC-AUC: 0.9931)
- ğŸ“¦ Registry centralisÃ© pour versioning des modÃ¨les
- ğŸ”— URL DagsHub : https://dagshub.com/YessineK/Mlops_Project

---

### **2ï¸âƒ£ Phase CI/CD : Automatisation avec Jenkins**

#### **DÃ©clenchement Automatique via Webhook**
```bash
# Workflow automatique
Nouvelle data ajoutÃ©e â†’ Git push â†’ GitHub Webhook â†’ Jenkins Pipeline
```

**Configuration Webhook GitHub** :
- **Payload URL** : `https://YOUR_NGROK_URL/github-webhook/`
- **Events** : Push events
- **RÃ©sultat** : Jenkins dÃ©marre automatiquement Ã  chaque push

#### **Pipeline Jenkins (Jenkinsfile)**
```groovy
pipeline {
    stages {
        stage('ğŸ“¥ Clone Repository')       # Clone du code depuis GitHub
        stage('ğŸ Setup Python')           # Installation dÃ©pendances
        stage('ğŸ“Š Register Best Model')    # Copie du modÃ¨le depuis registry
        stage('ğŸ“Š Data Drift Monitoring')  # Evidently : dÃ©tection drift
        stage('ğŸ“„ Archive Reports')        # Sauvegarde rapports HTML/JSON
        stage('ğŸ“Š Publish Reports')        # Docker container (port 9000)
        stage('ğŸ³ Build Docker Images')    # Build Backend + Frontend
        stage('ğŸš€ Push to Docker Hub')     # Push images vers registry
        stage('ğŸš€ Deploy Application')     # docker-compose up
        stage('ğŸ¥ Health Check')           # Validation dÃ©ploiement
    }
}
```

**Jenkins exÃ©cute automatiquement** :
1. âœ… Validation de la structure du projet
2. âœ… Enregistrement du modÃ¨le depuis `model_registry/`
3. âœ… Monitoring avec Evidently (drift + performance)
4. âœ… Build des images Docker (Backend FastAPI + Frontend Streamlit)
5. âœ… Push vers Docker Hub (`yessinekarray/churn-backend`, `churn-frontend`)
6. âœ… DÃ©ploiement avec `docker-compose`
7. âœ… Health checks des services

---

### **3ï¸âƒ£ Phase Monitoring : Evidently AI pour Data Drift**
```python
# monitoring/ - DÃ©tection automatique de drift
â”œâ”€â”€ prepare_data.py              # PrÃ©paration des datasets
â”œâ”€â”€ score_data.py                # Scoring des nouvelles donnÃ©es
â”œâ”€â”€ run_monitoring.py            # GÃ©nÃ©ration rapports Evidently
â””â”€â”€ data/
    â”œâ”€â”€ churn2.csv               # Reference dataset (baseline)
    â””â”€â”€ prod_batch_*.csv         # Production batches (dÃ©tection auto)
```

**Evidently gÃ©nÃ¨re automatiquement** :
- ğŸ“Š **Data Drift Report** : Distribution des features (reference vs current)
- ğŸ“ˆ **Performance Report** : MÃ©triques du modÃ¨le en production
- âš ï¸ **Alerts** : Si drift dÃ©tectÃ© â†’ Jenkins notifie (logs + artifacts)
- ğŸŒ **Dashboard** : Rapports HTML accessibles sur `http://localhost:9000`

**DÃ©tection Automatique du Dernier Fichier** :
```python
# prepare_data.py dÃ©tecte automatiquement le fichier le plus rÃ©cent
def get_latest_prod_file(data_dir):
    prod_files = glob.glob(os.path.join(data_dir, "prod_batch_*.csv"))
    latest = max(prod_files, key=os.path.getmtime)  # Tri par date
    return latest
```

**Tests de Drift** :
- âœ… Data Stability Test
- âœ… Column Drift Test (Kolmogorov-Smirnov)
- âœ… Dataset Drift Test
- âš ï¸ Si **drift > seuil** â†’ Future : Auto-retraining

---

### **4ï¸âƒ£ Phase DÃ©ploiement : Containerisation Docker**

#### **Architecture Multi-Container**
```yaml
# docker-compose.yml
services:
  backend:                          # API FastAPI
    image: yessinekarray/churn-backend:latest
    ports: ["8000:8000"]
    volumes: ["./models:/app/processors/models"]  # ModÃ¨le externe (1 GB)
    
  frontend:                         # Interface Streamlit
    image: yessinekarray/churn-frontend:latest
    ports: ["8501:8501"]
    depends_on: [backend]
    
  monitoring:                       # Rapports Evidently
    image: monitoring-reports:latest
    ports: ["9000:80"]
```

**Optimisation : ModÃ¨le Externe (Docker Volume)** :
- âŒ **ProblÃ¨me** : ModÃ¨le de 1 GB â†’ Image Docker trop lourde
- âœ… **Solution** : ModÃ¨le stockÃ© sur host, montÃ© via volume
- ğŸš€ **RÃ©sultat** : Images Docker lÃ©gÃ¨res (~100 MB), push/pull rapides

---

## ğŸ“Š Performances du ModÃ¨le

### **Meilleur ModÃ¨le : LightGBM (Hyperparameter Tuning)**

| MÃ©trique      | Score  | DÃ©tails                                    |
|---------------|--------|--------------------------------------------|
| **ROC-AUC**   | 0.9931 | Excellente discrimination des classes      |
| **F1-Score**  | 0.9192 | Bon Ã©quilibre Precision/Recall             |
| **Precision** | 0.9023 | 90% des prÃ©dictions "Churn" sont correctes |
| **Recall**    | 0.9372 | 94% des vrais "Churn" dÃ©tectÃ©s             |

**ModÃ¨les ComparÃ©s** (trackÃ©s sur MLflow) :
- Logistic Regression (baseline)
- Random Forest
- XGBoost
- **LightGBM** â­ (meilleur)

---

## ğŸš€ Installation & DÃ©marrage

### **PrÃ©requis**
- Docker & Docker Compose
- Git
- Jenkins (pour CI/CD)
- ngrok (pour webhook GitHub)

### **1. Cloner le Repository**
```bash
git clone https://github.com/YessineK/Mlops_Project.git
cd Mlops_Project
```

### **2. Configuration Jenkins**

**Installer Jenkins** :
```bash
docker run -d -p 8080:8080 -p 50000:50000 \
  -v jenkins_home:/var/jenkins_home \
  --name jenkins jenkins/jenkins:lts
```

**Configurer le Pipeline** :
1. CrÃ©er un projet Pipeline dans Jenkins
2. SCM : Git â†’ `https://github.com/YessineK/Mlops_Project.git`
3. Build Triggers : âœ… "GitHub hook trigger for GITScm polling"
4. Credentials Docker Hub : `docker-hub-credentials`

**Exposer Jenkins avec ngrok** :
```bash
ngrok http 8080
# Copier l'URL : https://YOUR_ID.ngrok-free.app
```

**Configurer Webhook GitHub** :
- Repository Settings â†’ Webhooks â†’ Add webhook
- Payload URL : `https://YOUR_ID.ngrok-free.app/github-webhook/`
- Content type : `application/json`
- Events : âœ… Just the push event

### **3. DÃ©ploiement Local (Sans Jenkins)**
```bash
# PrÃ©parer le modÃ¨le
mkdir -p models
cp notebooks/model_registry/best_model_final.pkl models/

# Lancer l'application
docker-compose up --build
```

**Services Accessibles** :
- ğŸ¨ **Frontend** : http://localhost:8501 (Interface utilisateur)
- ğŸ”Œ **Backend API** : http://localhost:8000/docs (Swagger UI)
- ğŸ“Š **Monitoring** : http://localhost:9000 (Rapports Evidently)

---

## ğŸ“ Structure du Projet
```
Mlops_Project/
â”‚
â”œâ”€â”€ backend/src/                    # API FastAPI
â”‚   â”œâ”€â”€ main.py                     # Endpoints API (/predict, /health)
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ models/                 # ModÃ¨les ML (via volume)
â”‚   â”‚   â””â”€â”€ preprocessor.pkl        # Pipeline preprocessing
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/                       # Interface Streamlit
â”‚   â”œâ”€â”€ app.py                      # UI utilisateur
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ notebooks/                      # ML Experimentation
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb     # MLflow tracking
â”‚   â”œâ”€â”€ 03_model_evaluation.ipynb
â”‚   â”œâ”€â”€ model_registry/
â”‚   â”‚   â””â”€â”€ best_model_final.pkl    # Meilleur modÃ¨le (1 GB)
â”‚   â””â”€â”€ processors/                 # Preprocessors versionnÃ©s
â”‚
â”œâ”€â”€ monitoring/                     # Evidently AI Monitoring
â”‚   â”œâ”€â”€ prepare_data.py             # DÃ©tection auto dernier fichier
â”‚   â”œâ”€â”€ score_data.py               # Scoring production
â”‚   â”œâ”€â”€ run_monitoring.py           # GÃ©nÃ©ration rapports
â”‚   â”œâ”€â”€ Dockerfile                  # Container monitoring (nginx)
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ churn2.csv              # Reference dataset
â”‚       â””â”€â”€ prod_batch_*.csv        # Production batches
â”‚
â”œâ”€â”€ Jenkins/
â”‚   â””â”€â”€ register_best_model.py      # Copie modÃ¨le â†’ backend/
â”‚
â”œâ”€â”€ models/                         # ModÃ¨les pour dÃ©ploiement (host)
â”‚   â””â”€â”€ best_model_final.pkl        # MontÃ© via Docker volume
â”‚
â”œâ”€â”€ docker-compose.yml              # Orchestration multi-container
â”œâ”€â”€ Jenkinsfile                     # Pipeline CI/CD automatisÃ©
â”œâ”€â”€ .gitignore                      # Ignore *.pkl, *.csv (sauf monitoring)
â””â”€â”€ README.md
```

---

## ğŸ”§ Technologies UtilisÃ©es

### **Machine Learning**
- **scikit-learn** : Preprocessing, baseline models
- **LightGBM** : Gradient Boosting (best model)
- **imbalanced-learn** : SMOTE (class balancing)
- **pandas, numpy** : Data manipulation

### **MLOps & Tracking**
- **MLflow** : Experiment tracking, model registry
- **DagsHub** : Remote MLflow server (collaboration)
- **Evidently AI** : Data drift detection, model monitoring

### **CI/CD & Deployment**
- **Jenkins** : Pipeline automation (build, test, deploy)
- **Docker** : Containerization (Backend, Frontend, Monitoring)
- **Docker Hub** : Image registry (`yessinekarray/*`)
- **GitHub Webhooks** : Auto-trigger Jenkins on push
- **ngrok** : Expose Jenkins for webhook

### **Backend & Frontend**
- **FastAPI** : RESTful API (Python, Pydantic)
- **Streamlit** : Interactive web UI
- **uvicorn** : ASGI server

---

## ğŸ”® Perspectives Futures (Roadmap)

### **Phase 1 : Auto-Retraining** ğŸ¤–
```
Si drift dÃ©tectÃ© â†’ Retraining automatique
    â†“
Combine old + new data
    â†“
Train nouveau modÃ¨le
    â†“
Validation (compare performances)
    â†“
Si meilleur â†’ Deploy | Sinon â†’ Alerte
```

**ImplÃ©mentation** :
- Jenkinsfile : Stage "Auto-Retraining si Drift"
- Scripts : `retrain_with_new_data.py`, `validate_new_model.py`
- Seuil drift : 3+ colonnes â†’ dÃ©clenche retraining

### **Phase 2 : Model Storage Scalable** â˜ï¸
- **MinIO** (S3-compatible, self-hosted) pour stocker modÃ¨les
- Backend tÃ©lÃ©charge modÃ¨le au dÃ©marrage (alternative au volume)
- Versioning des modÃ¨les avec tags (v1.0, v1.1, etc.)

### **Phase 3 : Kubernetes Deployment** âš“
- Conversion docker-compose â†’ Kubernetes manifests
- Auto-scaling backend based on load
- Rolling updates sans downtime

### **Phase 4 : A/B Testing** ğŸ§ª
- DÃ©ployer 2 versions du modÃ¨le en parallÃ¨le
- Router 50% traffic â†’ Model A, 50% â†’ Model B
- Comparer performances en production rÃ©elle

### **Phase 5 : Real-Time Monitoring Dashboard** ğŸ“Š
- Grafana + Prometheus pour mÃ©triques temps rÃ©el
- Alertes Slack/Email si drift ou dÃ©gradation performance
- Historique des drifts et retrainings

---

## ğŸ“š Documentation ComplÃ©mentaire

### **APIs**
- **Backend Swagger** : http://localhost:8000/docs
  - `POST /predict` : PrÃ©diction churn (JSON input)
  - `GET /health` : Health check API

### **MLflow Tracking**
- **DagsHub UI** : https://dagshub.com/YessineK/Mlops_Project
  - Experiments, runs, metrics, parameters
  - Model artifacts download

### **Evidently Reports**
- **Monitoring Dashboard** : http://localhost:9000
  - `monitoring_report.html` : Data drift visualization
  - `performance_report.html` : Model performance metrics
  - `*.json` : Tests results (PASS/FAIL)

---

## ğŸ¤ Contribution

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre du **Master 2 Data Science - UniversitÃ© Claude Bernard Lyon 1**.

**Auteur** : Yessine Karray  
**LinkedIn** : [Yessine Karray](https://www.linkedin.com/in/yessine-karray/)  
**GitHub** : [YessineK](https://github.com/YessineK)

---

## ğŸ“„ Licence

MIT License - Libre d'utilisation pour l'Ã©ducation et la recherche.

---

## ğŸ™ Remerciements

- **MLflow Team** pour le tracking framework
- **Evidently AI** pour les outils de monitoring
- **DagsHub** pour l'hÃ©bergement MLflow gratuit
- **FastAPI & Streamlit** pour les frameworks modernes
- **Jenkins Community** pour le CI/CD open-source

---

**â­ Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  lui donner une Ã©toile sur GitHub !**